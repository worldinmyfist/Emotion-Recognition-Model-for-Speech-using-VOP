{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing important Packages and Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import scipy\n",
    "import os.path\n",
    "import librosa\n",
    "import _pickle as cPickle\n",
    "from python_speech_features import mfcc,delta,ssc,logfbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numfeatper=7\n",
    "mfc= 13\n",
    "dell=13\n",
    "sscc=26\n",
    "filtt=13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining function that extracts important features from the wave file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurex(filepath):\n",
    "    \n",
    "    #Reading the audio file\n",
    "    (rate,X) = wav.read(filepath)\n",
    "    \n",
    "    #Extracting features from the audio \n",
    "    ceps = mfcc(X,rate,numcep = mfc)\n",
    "    delt=delta(ceps,2)\n",
    "    sscz=ssc(X,rate)\n",
    "    filt=delta(delt,2)\n",
    "    \n",
    "    #Finding mean, max, min and other attributes from the extracted features\n",
    "    ls = []\n",
    "    for i in range(ceps.shape[1]):\n",
    "        temp = ceps[:,i]\n",
    "        lfeatures  = [np.mean(temp), np.var(temp), np.amax(temp), np.amin(temp),scipy.stats.kurtosis(temp), scipy.stats.skew(temp),scipy.stats.iqr(temp)]\n",
    "        temp2 = np.array(lfeatures)\n",
    "        ls.append(temp2)\n",
    "    ls2=[]\n",
    "    for i in range(delt.shape[1]):\n",
    "        dtemp = delt[:,i]\n",
    "        dlfeatures  = [np.mean(dtemp), np.var(dtemp), np.amax(dtemp), np.amin(dtemp),scipy.stats.kurtosis(dtemp), scipy.stats.skew(dtemp),scipy.stats.iqr(dtemp)]\n",
    "        dtemp2 = np.array(dlfeatures)\n",
    "        ls2.append(dtemp2)\n",
    "    ls3=[]\n",
    "    for i in range(sscz.shape[1]):\n",
    "        stemp = sscz[:,i]\n",
    "        slfeatures  = [np.mean(stemp), np.var(stemp), np.amax(stemp), np.amin(stemp),scipy.stats.kurtosis(stemp), scipy.stats.skew(stemp),scipy.stats.iqr(stemp)]\n",
    "        stemp3 = np.array(slfeatures)\n",
    "        ls3.append(stemp3)\n",
    "    ls4=[]\n",
    "    for i in range(filt.shape[1]):\n",
    "        ftemp=filt[:,i]\n",
    "        flfeatures=[np.mean(ftemp), np.var(ftemp), np.amax(ftemp), np.amin(ftemp),scipy.stats.kurtosis(ftemp), scipy.stats.skew(ftemp),scipy.stats.iqr(ftemp)]\n",
    "        ftemp4 = np.array(flfeatures)\n",
    "        ls4.append(ftemp4)\n",
    "    \n",
    "    \n",
    "    source = np.array(ls).flatten()\n",
    "    source = np.append(source, np.array(ls2).flatten())\n",
    "    source = np.append(source, np.array(ls3).flatten())\n",
    "    source = np.append(source, np.array(ls4).flatten())\n",
    "\n",
    "    return source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the function that maps all features to the emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 455)\n",
      "03a01Fa.wav\n",
      "03b01Td.wav\n",
      "14a05Lb.wav\n",
      "11a01Ld.wav\n",
      "08b09Wc.wav\n",
      "13a04Ta.wav\n",
      "08a01Na.wav\n",
      "11b02Wb.wav\n",
      "08a07La.wav\n",
      "11a01Wc.wav\n",
      "15a02Wb.wav\n",
      "15b03Nb.wav\n",
      "13b09Fc.wav\n",
      "08b10Tc.wav\n",
      "16b10Eb.wav\n",
      "14b09Ea.wav\n",
      "09b10Nd.wav\n",
      "15a01Fb.wav\n",
      "15b10Wa.wav\n",
      "16a04La.wav\n",
      "16a01Nc.wav\n",
      "09b03Ed.wav\n",
      "14a01Na.wav\n",
      "14b09Fc.wav\n",
      "16a02Wb.wav\n",
      "13a01Fd.wav\n",
      "14a01Aa.wav\n",
      "13b03Na.wav\n",
      "09b02Tb.wav\n",
      "12a02Ac.wav\n",
      "03a04Fd.wav\n",
      "12a01Wc.wav\n",
      "15a01Nb.wav\n",
      "14a02Ab.wav\n",
      "16b09La.wav\n",
      "10b02Aa.wav\n",
      "13b01Ab.wav\n",
      "03a04Ad.wav\n",
      "11a02Fb.wav\n",
      "10a07Aa.wav\n",
      "12a01Fb.wav\n",
      "13a02Lc.wav\n",
      "11b09Na.wav\n",
      "10b03Wb.wav\n",
      "10b10Fc.wav\n",
      "14b10Nb.wav\n",
      "13a01Ec.wav\n",
      "09a01Ea.wav\n",
      "08a02Tb.wav\n",
      "10b02Na.wav\n",
      "14b01Wc.wav\n",
      "09a01Fa.wav\n",
      "14a02Ea.wav\n",
      "11b01Eb.wav\n",
      "15b02Tc.wav\n",
      "03a05Wb.wav\n",
      "13a04Wc.wav\n",
      "10a01Nb.wav\n",
      "16a07Nb.wav\n",
      "14a07Aa.wav\n",
      "08a01Wc.wav\n",
      "15a02Ea.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-c8dacd2d44b9>:4: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  (rate,X) = wav.read(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09a02La.wav\n",
      "03b02La.wav\n",
      "14a02Fd.wav\n",
      "10a07Ta.wav\n",
      "12b10Wa.wav\n",
      "11b03Fc.wav\n",
      "15a01La.wav\n",
      "09b09Wa.wav\n",
      "09b03Fd.wav\n",
      "08b03Nb.wav\n",
      "03b01Nb.wav\n",
      "13a01Nb.wav\n",
      "10a02Fa.wav\n",
      "16a02Tc.wav\n",
      "14a01Wa.wav\n",
      "16a01Ec.wav\n",
      "11a01Nd.wav\n",
      "11a05Ad.wav\n",
      "09a01Nb.wav\n",
      "14b10Tc.wav\n",
      "12b02Na.wav\n",
      "09a04Wa.wav\n",
      "10a05Ld.wav\n",
      "08a01Fd.wav\n",
      "12a01Nb.wav\n",
      "12a01Lb.wav\n",
      "13b10La.wav\n",
      "14a04Tb.wav\n",
      "16a07Wa.wav\n",
      "10a01Wa.wav\n",
      "12b01Ta.wav\n",
      "03b10Na.wav\n",
      "16a01Fc.wav\n",
      "08b10Fd.wav\n",
      "11b09Ad.wav\n",
      "08a01Lc.wav\n",
      "15b01Ec.wav\n",
      "08a01Ab.wav\n",
      "11a05Td.wav\n",
      "(101, 455)\n",
      "(101,)\n"
     ]
    }
   ],
   "source": [
    "def read_emodb(img_cols=(mfc+sscc+dell+filtt)*numfeatper):\n",
    "    \n",
    "    #Defining directories to be used\n",
    "    rootdir = \"./emodbdata_test/wav/\"\n",
    "    \n",
    "    #Total number of files in Testing set\n",
    "    num = 101\n",
    "    \n",
    "    #Defining alphabet for each emotion\n",
    "    solns=['W','L','E','A','F','T','N']\n",
    "    \n",
    "    #Defining data\n",
    "    data=np.empty(shape=(num, img_cols))\n",
    "    print(data.shape)\n",
    "    \n",
    "    label = []\n",
    "    i=0\n",
    "    \n",
    "    #Iterating thru each wave file\n",
    "    for filename in os.listdir(rootdir):\n",
    "        \n",
    "        name = \"\".join(filename)\n",
    "        full_name = rootdir+name\n",
    "        print(filename)\n",
    "        \n",
    "        #Extracting features and giving labels\n",
    "        data[i]=featurex(full_name)\n",
    "        label.append(solns.index(filename[5]))\n",
    "        i=i+1\n",
    "    \n",
    "    #Attaching label to data   \n",
    "    label=np.array(label)\n",
    "    f = open('./emodb_test.pkl', 'wb')\n",
    "    cPickle.dump((data, label), f)\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    f.close()\n",
    "\n",
    "read_emodb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
